Propuesta integral (adaptada a un artículo de innovación curricular en Journal of Statistics and Data Science Education): enseñar inferencia causal desde experimentos controlados hasta “IA causal” (SCM/DAG y búsqueda causal)Nota de alcance y evidencia disponibleLa propuesta original incluye “causal ML/AI”. Con las referencias disponibles, puedo sustentar con evidencia (i) la unificación de enfoques estructurales, contrafactuales y manipulativos, incluyendo herramientas gráficas y el marco de Pearl (donde se incluye el do-cálculo) Pearl, 1995; , (ii) el uso de DAG/SCM como “lenguaje matemático” para integrar supuestos y conectar con identificación (Pearl, 2009; , Pearl, 1995; , (iii) la conexión entre independencia condicional y estructura causal y los procedimientos de búsqueda/descubrimiento causal típicos del cruce estadística–IA West, 2009), y (iv) componentes aplicados clave (diseños alternativos y fallas prácticas en RCT, discrepancias RCT vs no-RCT, datos faltantes/doble robustez, preferencias/DRPT, distribuciones contrafactuales, y retos en series temporales) Ioannidis (2001)–Asesh (2022). No puedo respaldar con estas fuentes afirmaciones específicas sobre técnicas modernas de “causal ML” (p. ej., double machine learning) porque no están en el set provisto; por ello, el componente “IA causal” se operacionaliza aquí como SCM/DAG + do-cálculo + búsqueda causal basada en independencia condicional (la parte más sólidamente sustentada por Pearl, 1995; , (Pearl, 2009; , West, 2009)).1. Enfoque del manuscrito: “innovación didáctica” con artefactos reproduciblesTipo de artículo propuesto: innovación curricular / guía pedagógica con (a) secuencia instruccional, (b) laboratorios reproducibles, y (c) evaluación de aprendizaje y de calidad de especificación causal.Contribución central (reformulación publicable de tu idea): en vez de un “lenguaje unificado” como tratado abstracto, entregar un pipeline de especificación causal que traduzca sistemáticamente:
1) pregunta en lenguaje natural → 2) intervención/estimando contrafactual → 3) DAG/SCM con supuestos → 4) estrategia de identificación (vía criterios gráficos/do-cálculo en el marco de Pearl) → 5) implementación estadística y diagnóstico de amenazas prácticas (no cumplimiento/atrición, evidencia observacional vs experimental, missingness, preferencias, series temporales) (Pearl, 2009; , Pearl, 1995; , Ioannidis (2001)–Asesh (2022).Justificación: Pearl plantea explícitamente que los diagramas causales son un lenguaje matemático para integrar información estadística y sustantiva y para “consultar” si los supuestos bastan para identificar efectos causales en datos no experimentales, y, si es posible, derivar expresiones del efecto en términos observables (y si no, sugerir observaciones o experimentos auxiliares) (Pearl, 2009; . Además, su tratado posterior articula una teoría que unifica enfoques probabilísticos, manipulativos, contrafactuales y estructurales, lo que fundamenta pedagógicamente una enseñanza “traductora” entre paradigmas sin perder rigor Pearl, 1995; . Spirtes et al. muestran cómo la conexión independencia condicional–estructura causal es esencial para procedimientos de búsqueda causal, ofreciendo un puente natural hacia la dimensión “IA” (causal discovery) dentro de un curso de estadística/ciencia de datos West, 2009).2. Objetivos de aprendizaje (Learning Outcomes) alineados con la literatura causalAl finalizar la secuencia, el estudiantado será capaz de:LO1 (Especificación): Formular una pregunta causal como contraste entre escenarios/intervenciones, distinguiéndola de asociación estadística, y declarar el estimando (qué efecto causal se busca) en términos contrafactuales Pearl, 1995; , (Pearl, 2009; , West, 2009).LO2 (Lenguaje gráfico): Construir un DAG/SCM mínimo que codifique supuestos causales (confusión, mediación, colisión) y usarlo como lenguaje para justificar decisiones analíticas (p. ej., qué ajustar y qué no) (Pearl, 2009; , Pearl, 1995; .LO3 (Identificación como “diagnóstico” didáctico): Determinar si el efecto es identificable bajo los supuestos declarados (y, si aplica, derivar la expresión de ajuste mediante razonamiento gráfico/do-cálculo en el marco de Pearl), o justificar por qué no lo es y qué datos/experimentos auxiliares se requerirían (Pearl, 2009; , Pearl, 1995; .LO4 (Diseño y validez): Explicar por qué los RCT son preferibles cuando factibles, pero también por qué fallan supuestos (atrición, no cumplimiento) y por qué se recurre a diseños alternativos; discutir la incertidumbre adicional de estimaciones en alternativas Ioannidis (2001).LO5 (Evidencia experimental vs observacional): Interpretar y discutir discrepancias empíricas entre evidencia aleatorizada y no aleatorizada, vinculándolas con supuestos/diseños y con la necesidad de especificación transparente Marcus et al. (2012), Ioannidis (2001).LO6 (Amenazas comunes y extensiones):Missingness: justificar por qué la falta de datos amenaza validez y aplicar un enfoque doblemente robusto que combina modelo de resultado y mecanismo de falta, vinculándolo con supuestos explícitos Bang & Robins (2005), Ioannidis (2001).Preferencia/adhesión: reconocer cuándo el estimando relevante es “randomización vs preferencia” y cómo diseños híbridos (DRPT) permiten estimarlo, clarificando la generalización Spirtes et al. (2001).Más allá de la media: formular efectos sobre la distribución contrafactual (cuantiles/distribución completa) y conectarlos con métodos de regresión e inferencia funcional Chernozhukov et al. (2009).Series temporales: describir retos particulares (ruido, eficiencia, alta dimensión) y cómo la especificación causal (dirección, retardos, cadenas) es parte del problema Asesh (2022).3. Diseño instruccional propuesto (módulos, actividades, productos)La secuencia está pensada para 6–8 semanas (adaptable). Cada módulo tiene (i) concepto, (ii) práctica guiada, (iii) producto evaluable con rúbrica.Módulo 1 — De asociación a causalidad: qué significa “efecto” en un curso de estadísticaConcepto: unificación de perspectivas (probabilística/estructural/contrafactual/manipulativa) como base para definir “pregunta causal” de manera no ambigua Pearl, 1995; .Actividad: reescribir preguntas típicas de regresión (“X predice Y”) a forma intervencional (“¿qué pasaría con Y si intervenimos X?”), conectando con la idea de traducción entre paradigmas Pearl, 1995; , West, 2009).Producto: “Ficha de especificación causal v0” (pregunta, población, intervención, outcome, estimando tentativo).Módulo 2 — DAG/SCM como lenguaje matemático de supuestosConcepto: DAG como lenguaje para integrar conocimiento sustantivo y estadístico; consulta del grafo para evaluar suficiencia de supuestos e informar identificación/observación adicional (Pearl, 2009; .Actividad: construir DAG para 3 viñetas aplicadas (salud/educación/política), identificando confusores, mediadores y colisionadores.Producto: DAG mínimo + lista explícita de supuestos (p. ej., ausencia de confusión no medida) anclada al diagrama (Pearl, 2009; , Pearl, 1995; .Módulo 3 — Identificación como diagnóstico: de DAG a expresión (y al “no se puede”)Concepto: uso del marco de Pearl para pasar del grafo a expresiones de efecto causal cuando es identificable; si no lo es, qué observaciones/experimentos auxiliares ayudarían (Pearl, 2009; , Pearl, 1995; .Actividad: ejercicios de “backdoor/frontdoor” (cuando aplique) y discusión de cuándo una regresión ajustada es consistente con el DAG.Producto: “Justificación de ajuste” (por qué ajustar un set y por qué NO ajustar otro), referenciando el DAG como argumento formal (Pearl, 2009; .Módulo 4 — Diseño: RCT, fallas prácticas y alternativasConcepto: por qué el RCT es preferible si factible, pero supuestos pueden fallar (atrición, no cumplimiento) y pueden ser inviables/antiéticos; alternativas permiten responder más preguntas pero con mayor incertidumbre en magnitudes Ioannidis (2001).Actividad: rediseñar un RCT imposible a un diseño alternativo; listar amenazas a la validez y cómo la especificación causal cambia.Producto: memo de diseño (RCT vs alternativa) conectando el estimando con el diseño Ioannidis (2001), Pearl, 1995; .Módulo 5 — Por qué importa la especificación: discrepancias RCT vs observacionalConcepto: evidencia de que, aunque haya correlación entre RCT y estudios no aleatorizados, son frecuentes discrepancias en magnitudes de efecto más allá del azar Marcus et al. (2012).Actividad: lectura guiada y debate: “¿qué supuestos/diseños podrían explicar discrepancias?” conectándolo a la necesidad de hacer explícito el modelo causal Ioannidis (2001), (Pearl, 2009; .Producto: crítica estructurada de un estudio observacional (qué supuestos faltan, qué DAG implícito hay).Módulo 6 — Amenazas y extensiones (tres laboratorios “ciencia de datos causal”)Lab 6A: Missingness y doble robustezBase: missing outcome como amenaza principal y estimación doblemente robusta usando (i) regresión del outcome y (ii) modelo del mecanismo de falta; consistencia si al menos uno está bien especificado Bang & Robins (2005).Producto: notebook reproducible con comparación “análisis ingenuo vs doble robustez” y declaración explícita de supuestos Bang & Robins (2005), Ioannidis (2001).Lab 6B: Preferencia/adhesión y generalización (DRPT)Base: DRPT estima el efecto causal de asignación aleatoria vs elección/preferencia; motivación: compromiso/motivación puede cambiar con preferencia y afectar generalización Spirtes et al. (2001), en línea con preocupaciones prácticas del diseño Ioannidis (2001).Producto: simulación o reanálisis simple con interpretación del estimando “randomization vs preference” Spirtes et al. (2001).Lab 6C: Distribuciones contrafactuales (más allá de ATE)Base: herramientas de inferencia para distribuciones contrafactuales usando métodos de regresión (incluyendo distribución completa y cuantiles) y construcción de bandas de confianza funcionales Chernozhukov et al. (2009).Producto: reporte breve que compare “efecto promedio” vs “efectos en cuantiles/distribución”, explicitando el escenario contrafactual Chernozhukov et al. (2009), Pearl, 1995; .(Opcional) Módulo 7 — Series temporales y causalidad: especificación bajo ruido y alta dimensiónBase: retos de inferir causalidad desde series temporales observacionales: resiliencia al ruido, eficiencia computacional e inferencia en alta dimensión; además de dirección causal, retardos y cadenas Asesh (2022).Producto: mini-proyecto con especificación de lags/cadena causal y discusión de supuestos Asesh (2022), (Pearl, 2009; .(Transversal) Componente “IA causal” sustentado: búsqueda causal / independencia condicionalBase: Spirtes et al. enfatizan que conectar independencia condicional con estructura causal es esencial para procedimientos de descubrimiento causal y discuten conexiones con el marco de Rubin, constituyendo el puente natural a la parte “AI” en un curso de datos West, 2009), coherente con el rol central de grafos/estructura en el enfoque de Pearl (Pearl, 2009; , Pearl, 1995; .Actividad transversal: ejercicios donde se comparan (i) DAG propuesto por conocimiento de dominio vs (ii) hipótesis de estructura sugerida por patrones de independencia condicional (a nivel conceptual, sin prometer software específico) West, 2009), (Pearl, 2009; .4. Diseño de evaluación del aprendizaje (para reportarlo como paper)Para que el artículo sea publicable como innovación educativa, la evaluación debe mostrar evidencia de logro de outcomes con instrumentos transparentes. Aquí se propone una evaluación “ligera” y compatible con limitaciones reales (atrition/no compliance), que West discute como problemas frecuentes incluso en contextos experimentales Ioannidis (2001), y que puede beneficiarse de enfoques que hagan explícitas amenazas (p. ej., missingness) Bang & Robins (2005).4.1. Datos a recolectar (mínimo viable)Pre-test / post-test conceptual sobre: especificación causal, lectura de DAG, identificación como diagnóstico, y amenazas (missingness, discrepancias diseño-evidencia) (Pearl, 2009; , Marcus et al. (2012), Bang & Robins (2005).Artefactos evaluables: fichas de especificación, DAGs, justificaciones de ajuste, notebooks de labs (DR, DRPT, contrafactual distributions) (Pearl, 2009; , Bang & Robins (2005)–Chernozhukov et al. (2009).Eventos de no cumplimiento/atrición del curso (si los hay) como parte del reporte de validez interna/externa de la evaluación, consistente con preocupaciones prácticas descritas por West Ioannidis (2001).4.2. Análisis sugerido (simple, defendible)Comparación pre vs post en puntajes de rúbrica (medias y distribuciones), con discusión de amenazas si hay atrición/no respuesta (en línea con los problemas de atrición y falta de datos subrayados por West y Bang & Robins) Ioannidis (2001), Bang & Robins (2005).Análisis descriptivo de errores típicos: ajustes indebidos (p. ej., ajustar colisionadores), preguntas no intervencionales, ausencia de supuestos, etc., usando el DAG como referencia formal (Pearl, 2009; , Pearl, 1995; .Discusión de por qué la mejora en especificación es relevante para interpretar discrepancias entre evidencias experimentales y no experimentales (Ioannidis) Marcus et al. (2012) y para seleccionar diseños alternativos con claridad sobre incertidumbre (West) Ioannidis (2001).5. Pipeline paso a paso para ejecutar el proyecto (y convertirlo en artículo)A continuación, un pipeline operativo (12 pasos) para que el proyecto sea ejecutable en un semestre y quede listo para enviar.Fase A — Preparación (4–6 semanas)Paso 1. Alineación editorial (1 semana).Definir el formato como “innovación curricular” con materiales reproducibles (plantillas, rúbricas, notebooks). Enfatizar que el DAG es el lenguaje integrador y consultable para supuestos/identificación (Pearl, 2009; , dentro del marco unificador de causalidad Pearl, 1995; , y con puente a búsqueda causal (IA) vía independencia condicional West, 2009).Paso 2. Definir outcomes y mapa de contenidos (1 semana).Mapear LO1–LO6 (y LO7 opcional) a módulos/actividades, asegurando cobertura explícita de: diseños alternativos/limitaciones del RCT Ioannidis (2001), discrepancias RCT vs no-RCT Marcus et al. (2012), missingness/doble robustez Bang & Robins (2005), preferencia/DRPT Spirtes et al. (2001), distribuciones contrafactuales Chernozhukov et al. (2009), y series temporales Asesh (2022).Paso 3. Construir la “Ficha de especificación causal” (1 semana).Plantilla de 1–2 páginas: (i) pregunta en lenguaje natural, (ii) intervención, (iii) población, (iv) outcome, (v) estimando, (vi) DAG, (vii) estrategia de identificación/diagnóstico, (viii) amenazas y mitigaciones (missingness, no cumplimiento, preferencia) (Pearl, 2009; , Pearl, 1995; , Ioannidis (2001), Bang & Robins (2005), Spirtes et al. (2001).Paso 4. Diseñar instrumentos de evaluación (1–2 semanas).Pre/post test con ítems anclados a los principios de DAG como lenguaje y a la unificación conceptual (Pearl, 2009; , Pearl, 1995; .Preparar tareas que evidencien habilidades con missingness (DR) Bang & Robins (2005), DRPT Spirtes et al. (2001) y contrafactual distributions Chernozhukov et al. (2009).Definir protocolo para manejar no respuesta/atrición en la evaluación (relevante por las fallas prácticas destacadas por West) Ioannidis (2001), Bang & Robins (2005).Paso 5. Preparar datasets y notebooks (1 semana).Incluir al menos un dataset con missingness (para DR) Bang & Robins (2005) y uno con outcome continuo apto para análisis distribucional Chernozhukov et al. (2009). Si se incluye time series, seleccionar series simples y documentar retos de ruido/alta dimensión Asesh (2022).Fase B — Implementación (6–10 semanas)Paso 6. Aplicar pre-test y recolectar línea base (semana 1 del módulo).Registrar también variables de contexto (experiencia previa) para interpretar heterogeneidad, coherente con la idea de que evidencia y magnitudes pueden variar por diseño/población Marcus et al. (2012), Ioannidis (2001).Paso 7. Dictar Módulos 1–3 (semanas 1–3).Entregar habilidades nucleares: especificación + DAG + diagnóstico de identificación (y do-cálculo como parte del marco de Pearl, si el nivel lo permite) (Pearl, 2009; , Pearl, 1995; .Paso 8. Dictar Módulos 4–5 (semanas 4–5).Conectar especificación con diseño realista (alternativas al RCT) Ioannidis (2001) y con interpretación crítica de discrepancias RCT vs no-RCT Marcus et al. (2012).Paso 9. Dictar Laboratorios 6A–6C (semanas 6–8).Missingness y doble robustez Bang & Robins (2005).Preferencia y DRPT Spirtes et al. (2001).Contrafactual distributions Chernozhukov et al. (2009).A lo largo, reforzar la traducción pregunta → estimando → supuestos (DAG) → método (Pearl, 2009; , Pearl, 1995; .Paso 10 (opcional). Módulo 7 de series temporales (semana 9).Enfatizar que “especificar” (dirección, lags, cadenas) es parte del problema bajo ruido/alta dimensión Asesh (2022), y conectar con lenguaje gráfico/estructura (Pearl, 2009; , West, 2009).Fase C — Cierre y escritura (3–5 semanas)Paso 11. Post-test + evaluación final de artefactos (1 semana).Aplicar rúbrica (ver sección 6) a fichas, DAGs, y notebooks; documentar faltantes/atrición como amenaza y cómo se manejó (en línea con Ioannidis (2001), Bang & Robins (2005)).Paso 12. Redacción del artículo y paquete reproducible (2–4 semanas).Estructura sugerida:Introducción (necesidad de lenguaje integrador: DAG como lenguaje (Pearl, 2009; ; unificación conceptual Pearl, 1995; ; puente a IA/búsqueda causal West, 2009)).Diseño curricular (módulos y racional: diseños alternativos Ioannidis (2001), discrepancias Marcus et al. (2012), missingness Bang & Robins (2005), preferencia Spirtes et al. (2001), distribuciones contrafactuales Chernozhukov et al. (2009), time series Asesh (2022)).Evaluación (pre/post y rúbrica) con discusión de amenazas (atrición/missingness) Ioannidis (2001), Bang & Robins (2005).Resultados (mejoras por LO y errores típicos).Discusión (implicaciones para docencia en estadística y ciencia de datos; límites y próximos pasos).6. Rúbrica de evaluación: criterios e indicadores de logroLa rúbrica evalúa artefactos (ficha de especificación + DAG + justificación + notebook). Se recomienda 4 niveles: 1=Inicial, 2=En desarrollo, 3=Competente, 4=Avanzado. Los criterios están anclados en el rol del DAG como lenguaje y en la explicitación de supuestos/amenazas según la literatura causal provista (Pearl, 2009; , Pearl, 1995; , Ioannidis (2001)–Chernozhukov et al. (2009).Uso sugerido: aplicar en (i) tarea diagnóstica temprana (Módulo 2–3) y (ii) proyecto final (Módulo 6–7), para evidenciar progreso.
C1. Formulación de la pregunta causal y del estimando (LO1)Indicadores:
Pregunta expresada como intervención/contrafactual (no mera predicción) Pearl, 1995; , (Pearl, 2009; .Estimando definido (p. ej., efecto promedio, efecto distribucional) Pearl, 1995; , Chernozhukov et al. (2009).Niveles:
1: Pregunta asociacional (“X predice Y”), sin intervención ni estimando.2: Intervención sugerida pero estimando ambiguo.3: Intervención clara + estimando definido (ATE/ATT u otro).4: Además, justifica por qué ese estimando es relevante dadas condiciones reales/diseño (p. ej., preferencia, no cumplimiento) Spirtes et al. (2001), Ioannidis (2001).C2. DAG/SCM como representación explícita de supuestos (LO2)Indicadores:
DAG identifica confusores/mediadores/colisionadores coherentes con la narrativa (Pearl, 2009; , Pearl, 1995; .Supuestos listados y trazables al DAG (Pearl, 2009; .Niveles:
1: No hay DAG o es decorativo.2: DAG incompleto o no corresponde a la historia causal.3: DAG coherente + supuestos explícitos.4: Incluye discusión de variables no medidas/posibles violaciones y su impacto (Pearl, 2009; , Ioannidis (2001).C3. Identificación/diagnóstico (LO3)Indicadores:
Explica si el efecto es identificable bajo el DAG; si lo es, deriva/explica la expresión de ajuste (p. ej., por criterios gráficos; do-cálculo si procede) (Pearl, 2009; , Pearl, 1995; .Si no es identificable, propone datos/experimentos auxiliares (según la lógica de Pearl) (Pearl, 2009; .Niveles:
1: Ajuste “porque sí” (p-values/regresión sin justificación causal).2: Ajuste parcialmente justificado (lista de covariables sin conexión formal).3: Ajuste coherente con DAG y diagnóstico de identificabilidad.4: Además, argumenta alternativas de recolección o diseños auxiliares cuando no hay identificación (Pearl, 2009; , Ioannidis (2001).C4. Coherencia diseño–estimando–análisis (LO4–LO5)Indicadores:
Reconoce límites del RCT y justifica alternativas cuando aplique (atrición/no cumplimiento/ética) Ioannidis (2001).Discute cómo diferencias de diseño pueden explicar discrepancias entre RCT y no-RCT y por qué la especificación importa Marcus et al. (2012), Ioannidis (2001).Niveles:
1: Ignora el rol del diseño.2: Menciona limitaciones sin conectarlas al estimando.3: Conecta diseño con estimando y supuestos.4: Además, discute validez externa/generalización y discrepancias esperables entre diseños Marcus et al. (2012), Spirtes et al. (2001).C5. Tratamiento explícito de missingness (LO6—missing data)Indicadores:
Declara mecanismo asumido y su relación con covariables/tratamiento Bang & Robins (2005).Implementa o describe enfoque doblemente robusto y lo interpreta correctamente Bang & Robins (2005).Niveles:
1: Ignora missingness o hace “complete case” sin discusión.2: Reconoce missingness pero sin modelo/supuestos.3: Explicita supuestos y aplica DR (o justifica una alternativa).4: Además, discute sensibilidad y cómo missingness afecta validez, conectando con atrición/no cumplimiento Bang & Robins (2005), Ioannidis (2001).C6. Extensiones (seleccionar según módulo): preferencia (DRPT) / distribuciones contrafactuales / series temporalesPreferencia/DRPT (LO6): interpreta estimando “randomization vs preference” y su motivación (compromiso/motivación) Spirtes et al. (2001).Distribuciones contrafactuales (LO6): define y estima (o interpreta) efectos en cuantiles/distribución, no solo medias Chernozhukov et al. (2009).Series temporales (LO7 opcional): especifica dirección, retardo y cadena; discute ruido/alta dimensión Asesh (2022).Niveles: 1–4 según grado de especificación, coherencia con supuestos y calidad de interpretación, anclado a Spirtes et al. (2001)–Asesh (2022).7. Qué enviar como “paquete” (para maximizar evaluabilidad y replicabilidad)Plantilla (PDF/Markdown) + ejemplos resueltos (Pearl, 2009; , Pearl, 1995; .Rúbrica (tabla) + guía de uso con ejemplos de errores frecuentes (Pearl, 2009; , Ioannidis (2001), Bang & Robins (2005).Notebooks reproducibles: DR (missingness) Bang & Robins (2005), DRPT (simulación o reanálisis) Spirtes et al. (2001), contrafactual distributions Chernozhukov et al. (2009), y (opcional) time series Asesh (2022).Instrumentos pre/post (ítems) mapeados a LO1–LO6 con justificación teórica (DAG como lenguaje y unificación) (Pearl, 2009; , Pearl, 1995; , West, 2009).Referencias (IEEE)(Pearl, 2009;  J. Pearl, “Causal Diagrams for Empirical Research,” Biometrika, vol. 82, no. 4, pp. 669–688, 1995, doi: 10.2307/2337329 
Pearl, 1995; . J. Pearl, Causality: Models, Reasoning, and Inference, 2nd ed. Cambridge, U.K.: Cambridge Univ. Press, 2009, doi: 10.1017/cbo9780511803161 
West, 2009). P. Spirtes, C. Glymour, and R. Scheines, Causation, Prediction, and Search, 2nd ed. Cambridge, MA, USA: MIT Press, 2001, doi: 10.7551/mitpress/1754.001.0001 
Ioannidis (2001). S. G. West, “Alternatives to Randomized Experiments,” Current Directions in Psychological Science, vol. 18, no. 5, pp. 299–304, 2009, doi: 10.1111/j.1467-8721.2009.01656.x 
Marcus et al. (2012). J. P. A. Ioannidis et al., “Comparison of Evidence of Treatment Effects in Randomized and Nonrandomized Studies,” JAMA, vol. 286, no. 7, pp. 821–830, 2001, doi: 10.1001/jama.286.7.821 
Bang & Robins (2005). H. Bang and J. M. Robins, “Doubly Robust Estimation in Missing Data and Causal Inference Models,” Biometrics, vol. 61, no. 4, pp. 962–973, 2005, doi: 10.1111/j.1541-0420.2005.00377.x 
Spirtes et al. (2001). S. M. Marcus et al., “Estimating the causal effect of randomization versus treatment preference in a doubly randomized preference trial,” Psychological Methods, vol. 17, no. 2, pp. 244–254, 2012, doi: 10.1037/a0028031 
Chernozhukov et al. (2009). V. Chernozhukov, I. Fernández-Val, and B. Melly, “Inference on Counterfactual Distributions,” 2009, doi: 10.48550/arxiv.0904.0951 
Asesh (2022). A. Asesh, “Causal Inference – Time Series,” 2022, doi: 10.1007/978-3-031-11432-8_4.
References:Asesh, A. (2022). Causal Inference - Time Series., 43-51. https://doi.org/10.1007/978-3-031-11432-8_4Asesh, A. (2022). Causal Inference - Time Series., 43-51. https://doi.org/10.1007/978-3-031-11432-8_4Bang, H. and Robins, J. (2005). Doubly Robust Estimation in Missing Data and Causal Inference Models. Biometrics, 61(4), 962-973. https://doi.org/10.1111/j.1541-0420.2005.00377.xBang, H. and Robins, J. (2005). Doubly Robust Estimation in Missing Data and Causal Inference Models. Biometrics, 61(4), 962-973. https://doi.org/10.1111/j.1541-0420.2005.00377.xChernozhukov, V., Fernández‐Val, I., & Melly, B. (2009). Inference on Counterfactual Distributions.. https://doi.org/10.48550/arxiv.0904.0951Chernozhukov, V., Fernández‐Val, I., & Melly, B. (2009). Inference on Counterfactual Distributions.. https://doi.org/10.48550/arxiv.0904.0951Ioannidis, J. (2001). Comparison of Evidence of Treatment Effects in Randomized and Nonrandomized Studies. Jama, 286(7), 821. https://doi.org/10.1001/jama.286.7.821Ioannidis, J. (2001). Comparison of Evidence of Treatment Effects in Randomized and Nonrandomized Studies. Jama, 286(7), 821. https://doi.org/10.1001/jama.286.7.821Marcus, S., Stuart, E., Wang, P., Shadish, W., & Steiner, P. (2012). Estimating the causal effect of randomization versus treatment preference in a doubly randomized preference trial.. Psychological Methods, 17(2), 244-254. https://doi.org/10.1037/a0028031Marcus, S., Stuart, E., Wang, P., Shadish, W., & Steiner, P. (2012). Estimating the causal effect of randomization versus treatment preference in a doubly randomized preference trial.. Psychological Methods, 17(2), 244-254. https://doi.org/10.1037/a0028031Pearl, J. (1995). Causal Diagrams for Empirical Research. Biometrika, 82(4), 669. https://doi.org/10.2307/2337329Pearl, J. (1995). Causal Diagrams for Empirical Research. Biometrika, 82(4), 669. https://doi.org/10.2307/2337329Pearl, J. (2009). Causality.. https://doi.org/10.1017/cbo9780511803161Pearl, J. (2009). Causality.. https://doi.org/10.1017/cbo9780511803161Spirtes, P., Glymour, C., & Scheines, R. (2001). Causation, Prediction, and Search.. https://doi.org/10.7551/mitpress/1754.001.0001Spirtes, P., Glymour, C., & Scheines, R. (2001). Causation, Prediction, and Search.. https://doi.org/10.7551/mitpress/1754.001.0001West, S. (2009). Alternatives to Randomized Experiments. Current Directions in Psychological Science, 18(5), 299-304. https://doi.org/10.1111/j.1467-8721.2009.01656.xWest, S. (2009). Alternatives to Randomized Experiments. Current Directions in Psychological Science, 18(5), 299-304. https://doi.org/10.1111/j.1467-8721.2009.01656.x
